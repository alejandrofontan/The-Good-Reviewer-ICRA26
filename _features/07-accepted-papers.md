---
id: accepted-papers
name: Accepted Papers
heading: Accepted Papers
div_class: lead
# subheading: Will Catch Your Eye
# image: "http://placehold.it/500x500"
---

<div style="padding: 10px; border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;">
     <p><strong><span style="color: red;">Winner of the Outstanding Workshop Paper Award</span></strong></p>
    <strong>On the Potential of Visual Place Recognition for Visual SLAM</strong> 
    <a href="assets/proceedings/Schubert_RSS2025_WorkshopUnifyingVSLAM.pdf" style="text-decoration: none; color: #007bff;">[Paper]</a> 
    <a href="assets/proceedings/Schubert_Poster_RSS2025_WorkshopUnifyingVSLAM.pdf" style="text-decoration: none; color: #007bff;">[Poster]</a><br>
    Stefan Schubert<br>
</div>

<div style="padding: 10px; border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;">
    <p><strong><span style="color: red;">Winner of the Outstanding Workshop Open-Source Contribution Award</span></strong></p>
    <strong>Semantic pySLAM: Unifying semantic mapping approaches under the same benchmark </strong> 
    <a href="assets/proceedings/2025_RSSWS_SemanticSlam.pdf" style="text-decoration: none; color: #007bff;">[Paper]</a> 
    <br> David Morilla-Cabello, Eduardo Montijano<br>
</div>

<div style="padding: 10px; border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;">
    <!-- <p><strong><span style="color: red;">Winner of the Outstanding Workshop Presentation Award</span></strong></p> -->
    <strong>TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition</strong> 
    <a href="assets/proceedings/TAT_VPR_V1.pdf" style="text-decoration: none; color: #007bff;">[Paper]</a> 
    <a href="assets/proceedings/Oliver Grainge_poster.pdf" style="text-decoration: none; color: #007bff;">[Poster]</a><br>
    Oliver Grainge , Michael Milford , Indu Bodala , Sarvapali D. Ramchurn and Shoaib Ehsan<br>
</div>

<div style="padding: 10px; border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;">
    <!-- <p><strong><span style="color: red;">Winner of the Outstanding Workshop Presentation Award</span></strong></p> -->
    <strong>Structureless VIO</strong> 
    <a href="assets/proceedings/junlin Song_Paper_5.pdf" style="text-decoration: none; color: #007bff;">[Paper]</a> 
    <a href="assets/proceedings/junlin Song_Poster_5.pdf" style="text-decoration: none; color: #007bff;">[Poster]</a><br>
    Junlin Song and Miguel Olivares-Mendez<br>
</div>

<div style="padding: 10px; border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;">
    <!-- <p><strong><span style="color: red;">Winner of the Outstanding Workshop Presentation Award</span></strong></p> -->
    <strong>Bias-Eliminated PnP for Stereo Visual Odometry: Provably Consistent and Large-Scale Localization </strong> 
    <a href="assets/proceedings/Bias-Elim-Pnp.pdf" style="text-decoration: none; color: #007bff;">[Paper]</a> 
    <br> Guangyang Zeng, Yuan Shen, Ziyang Hong, Yuze Hong, Viorela Ila, Guodong Shi, Junfeng Wu<br>
</div>

<div style="padding: 10px; border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;">
    <!-- <p><strong><span style="color: red;">Winner of the Outstanding Workshop Presentation Award</span></strong></p> -->
    <strong>Night-Voyager: Consistent and Efficient Nocturnal Vision-Aided State Estimation in Object Maps </strong> 
    <a href="assets/proceedings/Night_Voyager_RSS_Workshop_2025.pdf" style="text-decoration: none; color: #007bff;">[Paper]</a> 
    <br> Tianxiao Gao, Mingle Zhao, Chengzhong Xu, and Hui Kong<br>
</div>

<script>
    document.addEventListener('DOMContentLoaded', function () {
        document.querySelectorAll('details').forEach(function(detail) {
            detail.addEventListener('toggle', function() {
                var icon = this.querySelector('#toggle-icon');
                if (this.open) {
                    icon.style.transform = 'rotate(90deg)';
                } else {
                    icon.style.transform = 'rotate(0deg)';
                }
            });
        });
    });
</script>

